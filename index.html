<!doctype html>
<html lang="en">
<head>
<title>HyperReel: High-Fidelity 6-DoF Video with Ray-Conditioned Sampling</title>
<link rel="stylesheet" href="resources/style.css"/>
<link rel="stylesheet" href="resources/glide.core.min.css">
<link rel="stylesheet" href="resources/glide.theme.min.css">
<link rel="stylesheet" href="resources/glide-custom.css">
<script src="resources/handlers.js"></script>
<script src="resources/glide.min.js"></script>
<script>
window.onload = function() {
  new Glide("#dynamic-carousel", {
    type: "carousel",
    perView: 1.68,
    focusAt: "center",
    autoplay: 3000,
    hoverpause: true
  }).mount();
  new Glide("#static-carousel", {
    type: "carousel",
    perView: 1.68,
    focusAt: "center",
    autoplay: 3000,
    hoverpause: true
  }).mount();
  new Glide("#realtime-carousel", {
    type: "carousel",
    perView: 2.05,
    focusAt: "center",
    autoplay: 3000,
    hoverpause: true
  }).mount();
};
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RZ6PES7EKD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-RZ6PES7EKD');
</script>
</head>
<body>
<h1 class="center">HyperReel: High-Fidelity 6-DoF Video with Ray-Conditioned Sampling</h1>
<h2 class="center">CVPR 2023 Highlight</h2>
<div class="authors">
  <div>
    <p><a href="https://www.battal.me/">Benjamin Attal</a></p>
    <p>Meta &amp; Carnegie Mellon University</p>
  </div>
  <div>
    <p><a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a></p>
    <p>Meta &amp; University of Maryland</p>
  </div>
  <div>
    <p><a href="https://richardt.name/">Christian Richardt</a></p>
    <p>Reality Labs Research</p>
  </div>
  <div>
    <p><a href="https://zollhoefer.com/">Michael Zollh&ouml;fer</a></p>
    <p>Reality Labs Research</p>
  </div>
  <div>
    <p><a href="https://johanneskopf.de/">Johannes Kopf</a></p>
    <p>Meta</p>
  </div>
  <div>
    <p><a href="https://www.cs.cmu.edu/~motoole2/">Matthew O'Toole</a></p>
    <p>Carnegie Mellon University</p>
  </div>
  <div>
    <p><a href="https://changilkim.com/">Changil Kim</a></p>
    <p>Meta</p>
  </div>
</div>

<!-- links -->
<div class="links">
  <a href="https://arxiv.org/abs/2301.02238"><span><img src="resources/file-earmark-pdf-fill.svg"/> Paper (arXiv)</span></a>
  <a href="results.html"><span><img src="resources/file-earmark-code-fill.svg"/> Supplemental Results</span></a>
  <a href="#teaser-video"><span><img src="resources/youtube.svg" style="height: 1.2em; vertical-align: -15%;"/> Teaser Video</span></a>
  <a href="https://github.com/facebookresearch/hyperreel"><span><img src="resources/github.svg"/> Code</span></a>
</div>

<div class="glide" id="dynamic-carousel">
  <div class="glide__track" data-glide-el="track">
    <ul class="glide__slides">
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/immersive_flames_0.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/immersive_truck_0.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/immersive_horse_50.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/signet_painter.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/signet_theater.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/signet_birthday.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/neural_3d_sear_steak_0.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/neural_3d_cook_spinach_0.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/neural_3d_beef_0.mov" type="video/mp4"/>
        </video>
      </li>
    </ul>
  </div>
  <div class="glide__arrows" data-glide-el="controls">
    <span class="glide__arrow glide__arrow--left" data-glide-dir="<"><img src="resources/arrow-left-circle-fill.svg"/></span>
    <span class="glide__arrow glide__arrow--right" data-glide-dir=">"><img src="resources/arrow-right-circle-fill.svg"/></span>
  </div>
  <div class="glide__bullets" data-glide-el="controls[nav]">
    <span class="glide__bullet" data-glide-dir="=0"></span>
    <span class="glide__bullet" data-glide-dir="=1"></span>
    <span class="glide__bullet" data-glide-dir="=2"></span>
    <span class="glide__bullet" data-glide-dir="=3"></span>
    <span class="glide__bullet" data-glide-dir="=4"></span>
    <span class="glide__bullet" data-glide-dir="=5"></span>
    <span class="glide__bullet" data-glide-dir="=6"></span>
    <span class="glide__bullet" data-glide-dir="=7"></span>
    <span class="glide__bullet" data-glide-dir="=8"></span>
  </div>
</div>
<p class="center shift-to-above">Dynamic 6-DoF rendering of scenes from <a href="https://github.com/augmentedperception/deepview_video_dataset">Google Immersive</a>, <a href="https://www.interdigital.com/data_sets/light-field-dataset">Technicolor</a>, and <a href="https://github.com/facebookresearch/Neural_3D_Video">Neural 3D Video</a> datasets.</p>

<div class="glide" id="static-carousel">
  <div class="glide__track" data-glide-el="track">
    <ul class="glide__slides">
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/ours_tarot_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/ours_cd.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/ours_lab.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/ours_tarot_small_1.mov" type="video/mp4"/>
        </video>
      </li>
    </ul>
  </div>
  <div class="glide__arrows" data-glide-el="controls">
    <span class="glide__arrow glide__arrow--left" data-glide-dir="<"><img src="resources/arrow-left-circle-fill.svg"/></span>
    <span class="glide__arrow glide__arrow--right" data-glide-dir=">"><img src="resources/arrow-right-circle-fill.svg"/></span>
  </div>
  <div class="glide__bullets" data-glide-el="controls[nav]">
    <span class="glide__bullet" data-glide-dir="=0"></span>
    <span class="glide__bullet" data-glide-dir="=1"></span>
    <span class="glide__bullet" data-glide-dir="=2"></span>
    <span class="glide__bullet" data-glide-dir="=3"></span>
  </div>
</div>
<p class="center shift-to-above">Static 6-DoF rendering of highly view-dependent scenes from <a href="https://vistec-my.sharepoint.com/:f:/g/personal/pakkapon_p_s19_vistec_ac_th/EnIUhsRVJOdNsZ_4smdhye0B8z0VlxqOR35IR3bp0uGupQ?e=TsaQgM">Shiny</a> and <a href="http://lightfield.stanford.edu/lfs.html">Stanford</a> datasets.</p>

<img src="figures/performance.png" style="display: block; width: 75%; margin: 0 auto;"/>
<p class="center shift-to-above">Speed-quality trade-off of our method compared to the state of the art.</p>

<h2>Abstract</h2>
<p class="justify">Volumetric scene representations enable photorealistic view synthesis for static scenes and form the basis of several existing 6-DoF video techniques.
However, the volume rendering procedures that drive these representations necessitate careful trade-offs in terms of quality, rendering speed, and memory efficiency. 
In particular, existing methods fail to simultaneously achieve real-time performance, small memory footprint, and high-quality rendering for challenging real-world scenes. 
To address these issues, we present HyperReel &mdash; a novel 6-DoF video representation.
The two core components of HyperReel are: 
(1) a ray-conditioned sample prediction network that enables high-fidelity, high frame rate rendering at high resolutions and 
(2) a compact and memory-efficient dynamic volume representation. 
Our 6-DoF video pipeline achieves the best performance compared to prior and contemporary approaches in terms of visual quality with small memory requirements, while also rendering at up to 18 frames-per-second at megapixel resolution without any custom CUDA code.</p>

<h2>Overview</h2>
<div class="justify">
  <p>
    Our sample prediction network, illustrated below, is unique compared to other approaches in that it
    both <em>accelerates</em> volume rendering and <em>improves</em> rendering quality,
    especially for challenging view dependent scenes.

    <br>
    <br>
    <img src="figures/pipeline.png" style="display: block; width: 100%; margin-left: auto; margin-right: auto;"/>
    <br>
    <br>

    The keyframe-based volume representation that we employ is an extension of <a href="https://apchenstu.github.io/TensoRF/">TensoRF [Chen et al. 2022]</a>.
    It compactly represents a full video sequence, consuming roughly the same amount of memory as a TensoRF for a <em>single static frame</em>.

    <br>
    <br>
    <img src="figures/dynamic.png" style="display: block; width: 70%; margin-left: auto; margin-right: auto;"/>
    <br>
    <br>

    The combination of our sample prediction network and keyframe-based volume representation comprise HyperReel, which achieves a balance between high rendering quality, speed, and memory efficiency
    that sets it apart from existing 6-DoF video representations.
  </p>
</div>

<h2 id="demo_videos">Real-Time Demos</h2>
<div class="justify">
<p>
  We show real-time demos of our approach at 512x512 pixel resolution applied to both dynamic and highly-view-dependent static scenes below.
  You can run our method and these real-time demos <a href="https://github.com/facebookresearch/hyperreel">using our codebase</a>.
</p>
</div>

<!-- real-time demo carousel -->
<div class="glide" id="realtime-carousel">
  <div class="glide__track" data-glide-el="track">
    <ul class="glide__slides">
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/technicolor_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/technicolor_2.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/immersive_2.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/immersive_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/shiny_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/shiny_2.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/stanford_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/stanford_2.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/donerf_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/donerf_2.mov" type="video/mp4"/>
        </video>
      </li>
    </ul>
  </div>
  <div class="glide__arrows" data-glide-el="controls">
    <span class="glide__arrow glide__arrow--left" data-glide-dir="<"><img src="resources/arrow-left-circle-fill.svg"/></span>
    <span class="glide__arrow glide__arrow--right" data-glide-dir=">"><img src="resources/arrow-right-circle-fill.svg"/></span>
  </div>
  <div class="glide__bullets" data-glide-el="controls[nav]">
    <span class="glide__bullet" data-glide-dir="=0"></span>
    <span class="glide__bullet" data-glide-dir="=1"></span>
    <span class="glide__bullet" data-glide-dir="=2"></span>
    <span class="glide__bullet" data-glide-dir="=3"></span>
    <span class="glide__bullet" data-glide-dir="=4"></span>
    <span class="glide__bullet" data-glide-dir="=5"></span>
    <span class="glide__bullet" data-glide-dir="=6"></span>
    <span class="glide__bullet" data-glide-dir="=7"></span>
    <span class="glide__bullet" data-glide-dir="=8"></span>
    <span class="glide__bullet" data-glide-dir="=9"></span>
  </div>
</div>

<h2 id="teaser-video">Teaser Video</h2>
<div class="center">
  <video controls style="width: 830px;" class="no-result">
    <source src="figures/hyperreel.mp4" type="video/mp4"/>
  </video>
</div>

<h2>BibTeX</h2>
<pre><code>@inproceedings{attal2023hyperreel,
  title     = {{HyperReel}: High-Fidelity {6-DoF} Video with Ray-Conditioned Sampling},
  author    = {Attal, Benjamin and Huang, Jia-Bin and Richardt, Christian and Zollhoefer, Michael and Kopf, Johannes and O'Toole, Matthew and Kim, Changil},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2023},
  arxiv     = {2301.02238},
}</code></pre>

<h2>Acknowledgements</h2>
<p>We thank Thomas Neff, Yu-Lun Liu, and Xiaoming Zhao
for valuable feedback and discussions, Zhaoyang Lv for
help running the Neural 3D Video Synthesis codebase,
and Liangchen Song for providing information about the
scenes from the Google Immersive Video dataset used in
NeRFPlayer. Matthew O'Toole acknowledges support
from NSF IIS-2008464.</p>

</body>
</html>
