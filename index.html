<!doctype html>
<html lang="en">
<head>
<title>HyperReel: High-Fidelity 6-DoF Video with Ray-Conditioned Sampling</title>
<link rel="stylesheet" href="resources/style.css"/>
<link rel="stylesheet" href="resources/glide.core.min.css">
<link rel="stylesheet" href="resources/glide.theme.min.css">
<link rel="stylesheet" href="resources/glide-custom.css">
<script src="resources/handlers.js"></script>
<script src="resources/glide.min.js"></script>
<script>
window.onload = function() {
  new Glide("#dynamic-carousel", {
    type: "carousel",
    // perView: 1.4,
    perView: 1.68,
    focusAt: "center",
    autoplay: 3000,
    hoverpause: true
  }).mount();
  new Glide("#static-carousel", {
    type: "carousel",
    perView: 1.68,
    focusAt: "center",
    autoplay: 3000,
    hoverpause: true
  }).mount();
  new Glide("#realtime-carousel", {
    type: "carousel",
    perView: 2.05,
    focusAt: "center",
    autoplay: 3000,
    hoverpause: true
  }).mount();
};
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CQVT3LMJLZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-CQVT3LMJLZ');
</script>
</head>
<body>
<h1 class="center">HyperReel: High-Fidelity 6-DoF Video with Ray-Conditioned Sampling</h1>
<div class="authors">
  <div>
    <p><a href="https://www.battal.me/">Benjamin Attal</a></p>
    <p>Carnegie Mellon University</p>
  </div>
  <div>
    <p><a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a></p>
    <p>Meta</p>
  </div>
  <div>
    <p><a href="https://richardt.name/">Christian Richardt</a></p>
    <p>Reality Labs Research</p>
  </div>
  <div>
    <p><a href="https://zollhoefer.com/">Michael Zollh&ouml;fer</a></p>
    <p>Reality Labs Research</p>
  </div>
  <div>
    <p><a href="https://johanneskopf.de/">Johannes Kopf</a></p>
    <p>Meta</p>
  </div>
  <div>
    <p><a href="https://www.cs.cmu.edu/~motoole2/">Matthew O'Toole</a></p>
    <p>Carnegie Mellon University</p>
  </div>
  <div>
    <p><a href="https://changilkim.com/">Changil Kim</a></p>
    <p>Meta</p>
  </div>
</div>

<!-- links -->
<div class="links">
  <a href="https://arxiv.org/abs/2112.01523"><span><img src="resources/file-earmark-pdf-fill.svg"/> Paper (arXiv)</span></a>
  <a href="results.html"><span><img src="resources/file-earmark-code-fill.svg"/> Supplemental Results</span></a>
  <!--
  <a href="#teaser-video"><span><img src="resources/youtube.svg" style="height: 1.2em; vertical-align: -15%;"/> Teaser Video</span></a>
  -->
  <a href="https://github.com/facebookresearch/hyperreel"><span><img src="resources/github.svg"/> Code</span></a>
</div>

<!--
<h2>Dynamic Scene Results</h2>
-->

<div class="glide" id="dynamic-carousel">
  <div class="glide__track" data-glide-el="track">
    <ul class="glide__slides">
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/immersive_flames_0.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/immersive_truck_0.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/immersive_horse_50.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/signet_painter.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/signet_theater.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/signet_trains.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/neural_3d_sear_steak_0.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/neural_3d_cook_spinach_0.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/neural_3d_beef_0.mov" type="video/mp4"/>
        </video>
      </li>
    </ul>
  </div>
  <div class="glide__arrows" data-glide-el="controls">
    <span class="glide__arrow glide__arrow--left" data-glide-dir="<"><img src="resources/arrow-left-circle-fill.svg"/></span>
    <span class="glide__arrow glide__arrow--right" data-glide-dir=">"><img src="resources/arrow-right-circle-fill.svg"/></span>
  </div>
  <div class="glide__bullets" data-glide-el="controls[nav]">
    <span class="glide__bullet" data-glide-dir="=0"></span>
    <span class="glide__bullet" data-glide-dir="=1"></span>
    <span class="glide__bullet" data-glide-dir="=2"></span>
    <span class="glide__bullet" data-glide-dir="=3"></span>
    <span class="glide__bullet" data-glide-dir="=4"></span>
    <span class="glide__bullet" data-glide-dir="=5"></span>
    <span class="glide__bullet" data-glide-dir="=6"></span>
    <span class="glide__bullet" data-glide-dir="=7"></span>
    <span class="glide__bullet" data-glide-dir="=8"></span>
  </div>
</div>
<p class="center">Dynamic 6-DoF rendering of scenes from Google Immersive, Technicolor, and Neural 3D Video datasets.</p>

<!--
<h2>Static Scene Results</h2>
-->

<div class="glide" id="static-carousel">
  <div class="glide__track" data-glide-el="track">
    <ul class="glide__slides">
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/ours_tarot_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/ours_cd.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/ours_lab.mov" type="video/mp4"/>
        </video>
      </li>
    </ul>
  </div>
  <div class="glide__arrows" data-glide-el="controls">
    <span class="glide__arrow glide__arrow--left" data-glide-dir="<"><img src="resources/arrow-left-circle-fill.svg"/></span>
    <span class="glide__arrow glide__arrow--right" data-glide-dir=">"><img src="resources/arrow-right-circle-fill.svg"/></span>
  </div>
  <div class="glide__bullets" data-glide-el="controls[nav]">
    <span class="glide__bullet" data-glide-dir="=0"></span>
    <span class="glide__bullet" data-glide-dir="=1"></span>
    <span class="glide__bullet" data-glide-dir="=2"></span>
  </div>
</div>
<p class="center">Static 6-DoF rendering of highly view-dependent scenes from Shiny and Stanford datasets.</p>

<!--
<h2>Method Performance</h2>
-->

<img src="figures/performance.png" style="display: block; width: 70%; margin: 1em auto;"/>
<p class="center">Speed-quality trade-off of our method compared to the state of the art.</p>

<h2>Abstract</h2>
<p class="justify">Volumetric scene representations enable photorealistic view synthesis for static scenes and form the basis of several existing 6-DoF video techniques.
However, the volume rendering procedures that drive these representations necessitate careful trade-offs in terms of quality, rendering speed, and memory efficiency. 
In particular, existing methods fail to simultaneously achieve real-time performance, small memory footprint, and high-quality rendering for challenging real-world scenes. 
To address these issues, we present HyperReel &mdash; a novel 6-DoF video representation.
The two core components of HyperReel are: 
(1) a ray-conditioned sample prediction network that enables high-fidelity, high frame rate rendering at high resolutions and 
(2) a compact and memory-efficient dynamic volume representation. 
Our 6-DoF video pipeline achieves the best performance compared to prior and contemporary approaches in terms of visual quality with small memory requirements, while also rendering at up to 18 frames-per-second at megapixel resolution without any custom CUDA code.</p>


<h2>Overview</h2>
<div class="justify">
  <p>
    Volumetric scene representations such as neural radiance fields [Mildenhall et al. 2020] and instant neural graphics primitives [MÃ¼ller et al. 2022] have recently made
    great strides towards photorealistic view synthesis for static scenes.

    While several recent works build dynamic view syntheisis pipelines on top of these volumetric representations,
    it remains a challenging task to create a 6-DoF video format that can achieve high quality, fast rendering, and a small memory footprint.

    <br>
    <br>

    We present <em>HyperReel</em>, a novel representation for 6-Degree-of-Freedom Video that achieves state-of-the-art quality
    while being memory efficient and real-time renderable at high-resolution. The two core components of HyperReel are:

    <ol>
        <li>A ray-conditioned sample prediciton network.</li>
        <li>A compact keyframe-based dynamic volume representation.</li>
    </ol>

    Our sample prediction network, illustrated below, is unique compared to other approaches in that it
    both <em>accelerates</em> volume rendering and <em>improves</em> rendering quality,</li>
    especially for challenging view dependent scenes.

    <br>
    <br>
    <img src="figures/pipeline.png" style="display: block; width: 100%; margin-left: auto; margin-right: auto;"/>
    <br>
    <br>

    The keyframe-based volume representation that we employ is an extension of TensoRF [Chen et al. 2022].
    It compactly represents a full video sequence, consuming roughly the same amount of memory as a TensoRF for a <em>single static frame</em>.

    <br>
    <br>
    <img src="figures/dynamic.png" style="display: block; width: 70%; margin-left: auto; margin-right: auto;"/>
    <br>
    <br>

    Additionally, our approach can render at up to 18 FPS at megapixel resolution, demonstrated in the <a href="#demo_videos">demo videos below</a>.

    In summary, HyperReel achieves a balance between high rendering quality, speed, and memory efficiency
    that sets it apart from existing 6-DoF video representations. 

  </p>
</div>

<!--
<div style="text-align: center;">
  <div class="flex" style="justify-content: space-between; align-items: center; margin-top: 2em;">
    <img src="figures/web_teaser.svg" style="display: block; width: 65%; margin-left:"/>
    <img src="figures/teaser_graph.svg" style="display: block; width: 34%; margin-left:"/>
  </div>
  <p>We present <em>Neural Light Fields with Ray-Space Embedding</em>, which map rays directly to integrated radiance.</p>
</div>
-->

<!--
<div class="flex" style="justify-content: space-between; align-items: center; margin-top: 2em;">
  <img src="figures/teaser_illustration.svg" style="width: 29%;"/>
  <img src="figures/teaser_visual.svg" style="width: 40%;"/>
  <img src="figures/teaser_graph.svg" style="width: 29%;"/>
</div>
<p class="justify">We present <em>Neural Light Fields with Ray-Space Embedding</em>, which map rays directly to integrated radiance (<em>left</em>). Our representation allows for high-quality view synthesis with faithful reconstruction of complex view dependence (<em>middle</em>). We are able to synthesize novel views in a fraction of the time required for the current state-of-the-art approaches, with comparable memory footprint. Our method achieves a more favorable trade-off between quality, speed, and memory than existing approaches for both dense and sparse light fields (<em>right</em>).</p>
-->

<h2 id="demo_videos">Real-Time Demos</h2>
<div class="justify">
<p>We show real-time demos of our approach at 512x512 pixel resolution applied to both dynamic and highly-view-dependent static scenes below.</p>
</div>

<!-- real-time demo carousel -->
<div class="glide" id="realtime-carousel">
  <div class="glide__track" data-glide-el="track">
    <ul class="glide__slides">
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/technicolor_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/technicolor_2.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/immersive_2.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/immersive_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/shiny_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/shiny_2.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/stanford_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/stanford_2.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/donerf_1.mov" type="video/mp4"/>
        </video>
      </li>
      <li class="glide__slide">
        <video controls muted loop autoplay>
          <source src="videos/donerf_2.mov" type="video/mp4"/>
        </video>
      </li>
    </ul>
  </div>
  <div class="glide__arrows" data-glide-el="controls">
    <span class="glide__arrow glide__arrow--left" data-glide-dir="<"><img src="resources/arrow-left-circle-fill.svg"/></span>
    <span class="glide__arrow glide__arrow--right" data-glide-dir=">"><img src="resources/arrow-right-circle-fill.svg"/></span>
  </div>
  <div class="glide__bullets" data-glide-el="controls[nav]">
    <span class="glide__bullet" data-glide-dir="=0"></span>
    <span class="glide__bullet" data-glide-dir="=1"></span>
    <span class="glide__bullet" data-glide-dir="=2"></span>
    <span class="glide__bullet" data-glide-dir="=3"></span>
    <span class="glide__bullet" data-glide-dir="=4"></span>
    <span class="glide__bullet" data-glide-dir="=5"></span>
    <span class="glide__bullet" data-glide-dir="=6"></span>
    <span class="glide__bullet" data-glide-dir="=7"></span>
    <span class="glide__bullet" data-glide-dir="=8"></span>
    <span class="glide__bullet" data-glide-dir="=9"></span>
  </div>
</div>


<!--
<h2 id="teaser-video">Teaser Video</h2>
<div style="margin-left: auto; margin-right: auto; text-align: center;">
  <video controls muted loop autoplay style="width: auto; height: auto; display: inline-block;">
    <source src="videos/teaser.mp4" type="video/mp4"/>
  </video>
</div>
-->

<h2>BibTeX</h2>
<pre><code>@unpublished{attal2023hyperreel,
  author = {Benjamin Attal and Jia-Bin Huang and Christian Richardt and Michael Zollhoefer and Johannes Kopf and Matthew O'Toole and Changil Kim},
  title  = {{HyperReel}: {H}igh-Fidelity {6-DoF} Video with Ray-Conditioned Sampling},
  year   = {2023},
  note   = {arXiv:2301.XXXXX}
}</code></pre>

</body>
</html>
